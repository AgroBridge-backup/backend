import{_ as s,c as e,o as i,ae as n}from"./chunks/framework.BQlYxExx.js";const u=JSON.parse('{"title":"Doc 6: Scalability & High Availability Policy","description":"","frontmatter":{},"headers":[],"relativePath":"technical/SCALABILITY.md","filePath":"technical/SCALABILITY.md","lastUpdated":1764098389000}'),t={name:"technical/SCALABILITY.md"};function l(r,a,o,c,p,d){return i(),e("div",null,[...a[0]||(a[0]=[n(`<h1 id="doc-6-scalability-high-availability-policy" tabindex="-1">Doc 6: Scalability &amp; High Availability Policy <a class="header-anchor" href="#doc-6-scalability-high-availability-policy" aria-label="Permalink to &quot;Doc 6: Scalability &amp; High Availability Policy&quot;">​</a></h1><blockquote><p><strong>Audience:</strong> DevOps, SRE, Cloud Architects, Business Leaders <strong>Objective:</strong> To outline the strategy for automated scaling and high availability of the AgroBridge API backend, ensuring the platform can handle growth and high-demand scenarios gracefully.</p></blockquote><hr><h2 id="english" tabindex="-1">English <a class="header-anchor" href="#english" aria-label="Permalink to &quot;English&quot;">​</a></h2><h3 id="_1-core-principles-for-a-scalable-system" tabindex="-1">1. Core Principles for a Scalable System <a class="header-anchor" href="#_1-core-principles-for-a-scalable-system" aria-label="Permalink to &quot;1. Core Principles for a Scalable System&quot;">​</a></h3><p>Our scalability strategy is built on modern cloud-native principles to ensure the platform is both resilient and cost-effective.</p><ul><li><strong>Immutability:</strong> Production containers are treated as disposable. We never modify a running container; instead, we deploy a new, updated version to replace it. This ensures predictability.</li><li><strong>Statelessness:</strong> The API service itself is &quot;stateless,&quot; meaning it doesn&#39;t store any session data locally. All state is externalized to the PostgreSQL database (for permanent data) and Redis (for temporary session data). This is the key that allows us to run many identical copies of the API simultaneously.</li><li><strong>Automation:</strong> Scaling, deployment, and recovery processes are automated to ensure rapid and reliable responses to changes in traffic.</li></ul><blockquote><p><strong>For Non-Technical Stakeholders: An Analogy for Autoscaling</strong> Imagine our backend is a supermarket. A single checkout counter is one API container.</p><ul><li>If a long line forms (high traffic), we don&#39;t ask the cashier to work faster (that&#39;s <strong>Vertical Scaling</strong>, and it has limits).</li><li>Instead, we automatically open more checkout counters (that&#39;s <strong>Horizontal Scaling</strong>).</li><li>The <strong>Load Balancer</strong> is the store manager directing new customers to the shortest line.</li><li>When the rush is over, we close the extra counters to save on electricity. This is how our system &quot;breathes&quot;—expanding and contracting to meet demand perfectly without wasting resources.</li></ul></blockquote><h3 id="_2-production-architecture-aws" tabindex="-1">2. Production Architecture (AWS) <a class="header-anchor" href="#_2-production-architecture-aws" aria-label="Permalink to &quot;2. Production Architecture (AWS)&quot;">​</a></h3><p>The recommended production architecture on AWS is designed for high availability and elasticity.</p><div class="language-mermaid vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">mermaid</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">graph TD</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    subgraph &quot;Internet&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        A[User/Client]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    end</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    subgraph &quot;AWS Cloud&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        B[Route 53 DNS] --&gt; C{Application Load Balancer};</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        subgraph &quot;VPC - Availability Zone 1&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            D1[ECS Task 1: API Container];</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            D2[ECS Task 2: API Container];</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        end</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        subgraph &quot;VPC - Availability Zone 2&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            E1[ECS Task 3: API Container];</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            E2[ECS Task 4: API Container];</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        end</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        C --&gt; D1;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        C --&gt; D2;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        C --&gt; E1;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        C --&gt; E2;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        subgraph &quot;Auto Scaling Group&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            direction LR</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            D1 &amp; D2 &amp; E1 &amp; E2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        end</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        F[RDS: PostgreSQL Multi-AZ]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        G[ElastiCache: Redis Multi-AZ]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        D1 &amp; D2 &amp; E1 &amp; E2 -- Connects to --&gt; F;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        D1 &amp; D2 &amp; E1 &amp; E2 -- Connects to --&gt; G;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    end</span></span></code></pre></div><ul><li><strong>Application Load Balancer (ALB):</strong> Distributes incoming traffic across multiple containers in different Availability Zones (AZs).</li><li><strong>Amazon ECS (Elastic Container Service):</strong> Manages the lifecycle of our Docker containers.</li><li><strong>Auto Scaling Group:</strong> Automatically adjusts the number of running containers based on demand.</li><li><strong>Multi-AZ Deployment:</strong> The API, database, and cache are all deployed across multiple physical data centers (AZs). If one data center fails, traffic is automatically rerouted, ensuring zero downtime for our users.</li></ul><h3 id="_3-autoscaling-policy-target-tracking" tabindex="-1">3. Autoscaling Policy (Target Tracking) <a class="header-anchor" href="#_3-autoscaling-policy-target-tracking" aria-label="Permalink to &quot;3. Autoscaling Policy (Target Tracking)&quot;">​</a></h3><ul><li><strong>Scaling Method:</strong> We use a &quot;Target Tracking&quot; policy, which is simpler and more effective than legacy step scaling. We set a target, and AWS does the work to keep our system at that target.</li><li><strong>Primary Trigger: CPU Utilization</strong><ul><li><strong>Target:</strong> We will set a target average CPU utilization of <strong>65%</strong>.</li><li><strong>Action:</strong> If the average CPU across all containers rises above 65%, AWS will automatically launch new containers to bring the average down. If it drops significantly below 65%, it will terminate unneeded containers to save costs.</li></ul></li></ul><h3 id="_4-comparison-to-industry-best-practices" tabindex="-1">4. Comparison to Industry Best Practices <a class="header-anchor" href="#_4-comparison-to-industry-best-practices" aria-label="Permalink to &quot;4. Comparison to Industry Best Practices&quot;">​</a></h3><ul><li><strong>ECS vs. Kubernetes (EKS):</strong> While Kubernetes is the de-facto industry standard for complex microservices, our current architecture is a well-structured monolith. <strong>Amazon ECS</strong> provides the ideal balance of power and simplicity for this stage, reducing operational overhead while still providing robust container orchestration. We retain the option to migrate to EKS in the future if our microservice needs become more complex.</li><li><strong>Containers vs. Serverless (Lambda):</strong> Serverless is excellent for event-driven or spiky, short-lived workloads. For a persistent API with steady traffic, a container-based approach offers better performance consistency and avoids cold-start latency issues, providing a smoother user experience.</li></ul><h3 id="_5-faq" tabindex="-1">5. FAQ <a class="header-anchor" href="#_5-faq" aria-label="Permalink to &quot;5. FAQ&quot;">​</a></h3><ul><li><strong>What is the difference between Horizontal and Vertical Scaling?</strong><ul><li><strong>Vertical Scaling</strong> is like upgrading to a more powerful server (more CPU/RAM). It&#39;s expensive and has a hard limit.</li><li><strong>Horizontal Scaling</strong> is adding more individual servers/containers. It&#39;s more flexible, resilient, and cost-effective, which is why we&#39;ve chosen this model.</li></ul></li></ul><hr><h2 id="espanol" tabindex="-1">Español <a class="header-anchor" href="#espanol" aria-label="Permalink to &quot;Español&quot;">​</a></h2><h3 id="_1-principios-fundamentales-para-un-sistema-escalable" tabindex="-1">1. Principios Fundamentales para un Sistema Escalable <a class="header-anchor" href="#_1-principios-fundamentales-para-un-sistema-escalable" aria-label="Permalink to &quot;1. Principios Fundamentales para un Sistema Escalable&quot;">​</a></h3><p>Nuestra estrategia de escalabilidad se basa en principios modernos nativos de la nube para garantizar que la plataforma sea resiliente y rentable.</p><ul><li><strong>Inmutabilidad:</strong> Los contenedores de producción se tratan como artefactos desechables. Nunca modificamos un contenedor en ejecución; en su lugar, desplegamos una nueva versión actualizada para reemplazarlo. Esto garantiza la previsibilidad.</li><li><strong>Sin Estado (Statelessness):</strong> El servicio de la API en sí mismo es &quot;sin estado&quot;, lo que significa que no almacena datos de sesión localmente. Todo el estado se externaliza a la base de datos PostgreSQL (para datos permanentes) y a Redis (para datos de sesión temporales). Esta es la clave que nos permite ejecutar muchas copias idénticas de la API simultáneamente.</li><li><strong>Automatización:</strong> Los procesos de escalado, despliegue y recuperación están automatizados para garantizar respuestas rápidas y fiables a los cambios en el tráfico.</li></ul><blockquote><p><strong>Para Stakeholders No Técnicos: Una Analogía para el Autoescalado</strong> Imagine que nuestro backend es un supermercado. Una única caja registradora es un contenedor de la API.</p><ul><li>Si se forma una larga fila (alto tráfico), no le pedimos al cajero que trabaje más rápido (eso es <strong>Escalado Vertical</strong>, y tiene límites).</li><li>En su lugar, abrimos automáticamente más cajas registradoras (eso es <strong>Escalado Horizontal</strong>).</li><li>El <strong>Balanceador de Carga</strong> es el gerente de la tienda que dirige a los nuevos clientes a la fila más corta.</li><li>Cuando pasa la hora punta, cerramos las cajas extra para ahorrar electricidad. Así es como nuestro sistema &quot;respira&quot;, expandiéndose y contrayéndose para satisfacer la demanda perfectamente sin desperdiciar recursos.</li></ul></blockquote><h3 id="_2-arquitectura-de-produccion-aws" tabindex="-1">2. Arquitectura de Producción (AWS) <a class="header-anchor" href="#_2-arquitectura-de-produccion-aws" aria-label="Permalink to &quot;2. Arquitectura de Producción (AWS)&quot;">​</a></h3><p>La arquitectura de producción recomendada en AWS está diseñada para alta disponibilidad y elasticidad.</p><div class="language-mermaid vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">mermaid</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">graph TD</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    subgraph &quot;Internet&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        A[Usuario/Cliente]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    end</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    subgraph &quot;Nube de AWS&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        B[Route 53 DNS] --&gt; C{Application Load Balancer};</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        subgraph &quot;VPC - Zona de Disponibilidad 1&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            D1[Tarea ECS 1: Contenedor API];</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            D2[Tarea ECS 2: Contenedor API];</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        end</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        subgraph &quot;VPC - Zona de Disponibilidad 2&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            E1[Tarea ECS 3: Contenedor API];</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            E2[Tarea ECS 4: Contenedor API];</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        end</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        C --&gt; D1;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        C --&gt; D2;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        C --&gt; E1;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        C --&gt; E2;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        subgraph &quot;Grupo de Autoescalado&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            direction LR</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            D1 &amp; D2 &amp; E1 &amp; E2</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        end</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        F[RDS: PostgreSQL Multi-AZ]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        G[ElastiCache: Redis Multi-AZ]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        D1 &amp; D2 &amp; E1 &amp; E2 -- Conectan a --&gt; F;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        D1 &amp; D2 &amp; E1 &amp; E2 -- Conectan a --&gt; G;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    end</span></span></code></pre></div><ul><li><strong>Application Load Balancer (ALB):</strong> Distribuye el tráfico entrante entre múltiples contenedores en diferentes Zonas de Disponibilidad (AZ).</li><li><strong>Amazon ECS (Elastic Container Service):</strong> Gestiona el ciclo de vida de nuestros contenedores Docker.</li><li><strong>Auto Scaling Group:</strong> Ajusta automáticamente el número de contenedores en ejecución según la demanda.</li><li><strong>Despliegue Multi-AZ:</strong> La API, la base de datos y la caché se despliegan en múltiples centros de datos físicos (AZ). Si un centro de datos falla, el tráfico se redirige automáticamente, garantizando cero tiempo de inactividad.</li></ul><h3 id="_3-politica-de-autoescalado-target-tracking" tabindex="-1">3. Política de Autoescalado (Target Tracking) <a class="header-anchor" href="#_3-politica-de-autoescalado-target-tracking" aria-label="Permalink to &quot;3. Política de Autoescalado (Target Tracking)&quot;">​</a></h3><ul><li><strong>Método de Escalado:</strong> Usamos una política de &quot;Target Tracking&quot; (seguimiento de objetivo), que es más simple y efectiva. Establecemos un objetivo y AWS se encarga de mantener nuestro sistema en ese objetivo.</li><li><strong>Disparador Principal: Uso de CPU</strong><ul><li><strong>Objetivo:</strong> Estableceremos un objetivo de uso medio de CPU del <strong>65%</strong>.</li><li><strong>Acción:</strong> Si el uso medio de CPU supera el 65%, AWS lanzará automáticamente nuevos contenedores. Si cae significativamente por debajo del 65%, terminará los contenedores innecesarios para ahorrar costos.</li></ul></li></ul><h3 id="_4-comparacion-con-mejores-practicas-de-la-industria" tabindex="-1">4. Comparación con Mejores Prácticas de la Industria <a class="header-anchor" href="#_4-comparacion-con-mejores-practicas-de-la-industria" aria-label="Permalink to &quot;4. Comparación con Mejores Prácticas de la Industria&quot;">​</a></h3><ul><li><strong>ECS vs. Kubernetes (EKS):</strong> Mientras que Kubernetes es el estándar de la industria para microservicios complejos, nuestra arquitectura actual es un monolito bien estructurado. <strong>Amazon ECS</strong> proporciona el equilibrio ideal de potencia y simplicidad para esta etapa, reduciendo la sobrecarga operativa. Mantenemos la opción de migrar a EKS en el futuro si nuestras necesidades de microservicios se vuelven más complejas.</li><li><strong>Contenedores vs. Serverless (Lambda):</strong> Serverless es excelente para cargas de trabajo event-driven o de corta duración. Para una API persistente con tráfico constante, un enfoque basado en contenedores ofrece un mejor rendimiento y evita problemas de latencia de &quot;arranque en frío&quot;, proporcionando una experiencia de usuario más fluida.</li></ul><h3 id="_5-faq-1" tabindex="-1">5. FAQ <a class="header-anchor" href="#_5-faq-1" aria-label="Permalink to &quot;5. FAQ&quot;">​</a></h3><ul><li><strong>¿Cuál es la diferencia entre Escalado Horizontal y Vertical?</strong><ul><li><strong>Escalado Vertical</strong> es como actualizar a un servidor más potente (más CPU/RAM). Es caro y tiene un límite estricto.</li><li><strong>Escalado Horizontal</strong> es añadir más servidores/contenedores individuales. Es más flexible, resiliente y rentable, por lo que hemos elegido este modelo.</li></ul></li></ul>`,34)])])}const g=s(t,[["render",l]]);export{u as __pageData,g as default};
